%&latex
\documentclass[letterpaper,11pt]{article}
\usepackage{graphicx}
\usepackage[margin=1.0in]{geometry}
\usepackage[hyphens]{url}
\usepackage{hyperref}

\makeatletter
\setlength{\@fptop}{0pt}
\makeatother

\title{TEBreak: Generalised insertion detection}
\author{Adam D. Ewing (adam.ewing@mater.uq.edu.au)}
\begin{document}
 \date{July 26, 2016}
 \maketitle

\section{Introduction}
\subsection{Software Dependencies and Installation}
TEBreak requires the following software packages be available:

\begin{enumerate}
  \item samtools (\url{http://samtools.sourceforge.net/})
  \item bwa (\url{http://bio-bwa.sourceforge.net/})
  \item LAST (\url{http://last.cbrc.jp/})
  \item minia (\url{http://minia.genouest.org/})
\end{enumerate}

Please run the included setup.py to check that external dependencies are installed properly and to install the required python libraries:

\begin{verbatim}
python setup.py build
python setup.py install
\end{verbatim}

\section{Testing / example run}
\subsection{Prepare reference genome}
Any number of variations on the human reference genome are available. To obtain the version used to generate the included example BAM please do the following:
\begin{verbatim}
wget ftp://ftp.ncbi.nlm.nih.gov/sra/reports/Assembly/GRCh37-HG19_Broad_variant/Homo_sapiens_assembly19.fasta
bwa index Homo_sapiens_assembly19.fasta
samtools faidx Homo_sapiens_assembly19.fasta
\end{verbatim}

\subsection{Run tebreak.py}

Starting in the TEBreak root directory:

\begin{verbatim}
tebreak/tebreak.py \
-b test/data/example.ins.bam \
-r Homo_sapiens_assembly19.fasta \
-i test/data/example.region.bed \
--pickle test/example.pickle \
--detail_out test/example.tebreak.detail.out
\end{verbatim}

Output should be similar to the following:

\begin{verbatim}
2015-07-19 17:16:05,185 commandline: tebreak/tebreak.py -b test/data/example.ins.bam -r Homo_sapiens_assembly19.fasta -i test/data/example.region.bed --pickle test/example.pickle --detail_out test/example.tebreak.detail.out
2015-07-19 17:16:05,186 loading bwa index /home/adam/dev/genomes/broad/Homo_sapiens_assembly19.fasta into shared memory ...
2015-07-19 17:16:05,192 loaded.
2015-07-19 17:16:05,244 chunk count: 1
2015-07-19 17:16:05,248 Processing chunk: 4:57459002-57496002 ...
2015-07-19 17:16:05,248 Chunk 4:57459002-57496002: Parsing split reads from bam(s): test/data/example.ins.bam ...
2015-07-19 17:16:05,364 Chunk 4:57459002-57496002: Building clusters from 151 split reads ...
2015-07-19 17:16:05,369 Chunk 4:57459002-57496002: Building breakends...
2015-07-19 17:16:05,616 Chunk 4:57459002-57496002: Mapping 74 breakends ...
2015-07-19 17:16:06,312 Chunk 4:57459002-57496002: Building insertions...
2015-07-19 17:16:06,333 Chunk 4:57459002-57496002: Processing and filtering 40 potential insertions ...
2015-07-19 17:16:06,456 Chunk 4:57459002-57496002: Postprocessing 6 filtered insertions, trying to improve consensus breakend sequences ...
2015-07-19 17:16:08,623 Chunk 4:57459002-57496002: Summarising insertions ...
2015-07-19 17:16:08,623 Finished chunk: 4:57459002-57496002
2015-07-19 17:16:08,635 Pickled to test/example.pickle
\end{verbatim}

\subsection{Run resolve.py}

The second step is to resolve putative insertions, in this case human transposable element insertions, using resolve.py:

\begin{verbatim}
tebreak/resolve.py \
-p test/example.pickle \
-i lib/teref.human.fa \
--detail_out test/example.resolve.detail.out \
-v > test/example.tab.txt
\end{verbatim}

You should see something like the following:

\begin{verbatim}
2015-07-19 17:25:39,039 resolve.py called with args: tebreak/resolve.py -p test/example.pickle -i lib/teref.human.fa --detail_out test/example.resolve.detail.out -v
2015-07-19 17:25:39,039 loading pickle: test/example.pickle
2015-07-19 17:25:39,044 finished loading test/example.pickle
2015-07-19 17:25:39,044 raw candidate count: 6
2015-07-19 17:25:39,044 prefiltered candidate count: 6
2015-07-19 17:25:39,044 Create LAST db for tebreak_refs/teref.human.fa ...
2015-07-19 17:25:39,093 submitted 0 candidates, last uuid: f7b95d73-07e9-4b6d-868b-6553c5a7c5f9
2015-07-19 17:25:39,120 Samtools indexing /tmp/tebreak.ref.ALU:AluYa5.f7b95d73-07e9-4b6d-868b-6553c5a7c5f9.fa ...
2015-07-19 17:25:39,128 Create BWA db for /tmp/tebreak.ref.ALU:AluYa5.f7b95d73-07e9-4b6d-868b-6553c5a7c5f9.fa ...
2015-07-19 17:25:39,253 Samtools indexing /tmp/tebreak.ref.L1:L1preTa.11f42f35-c098-4d56-b9eb-34d62b2b4faa.fa ...
2015-07-19 17:25:39,259 Create BWA db for /tmp/tebreak.ref.L1:L1preTa.11f42f35-c098-4d56-b9eb-34d62b2b4faa.fa ...
2015-07-19 17:25:39,370 Samtools indexing /tmp/tebreak.ref.L1:L1Ta.d9fa11ac-dd69-4267-8774-dc8ed6b312e7.fa ...
2015-07-19 17:25:39,376 Create BWA db for /tmp/tebreak.ref.L1:L1Ta.d9fa11ac-dd69-4267-8774-dc8ed6b312e7.fa ...
2015-07-19 17:25:39,502 Samtools indexing /tmp/tebreak.ref.ALU:AluYa5.4c1fa9a7-5fed-44c3-8ca3-84247090dd2c.fa ...
2015-07-19 17:25:39,508 Create BWA db for /tmp/tebreak.ref.ALU:AluYa5.4c1fa9a7-5fed-44c3-8ca3-84247090dd2c.fa ...
2015-07-19 17:25:39,643 Samtools indexing /tmp/tebreak.ref.ALU:AluYa5.f805e9b6-6922-47cf-bef3-b4d082e07e8d.fa ...
2015-07-19 17:25:39,649 Create BWA db for /tmp/tebreak.ref.ALU:AluYa5.f805e9b6-6922-47cf-bef3-b4d082e07e8d.fa ...
2015-07-19 17:25:39,745 Samtools indexing /tmp/tebreak.ref.SVA:SVA_F.1d70cd96-ed12-40ed-ba2c-3495a4db7b20.fa ...
2015-07-19 17:25:39,751 Create BWA db for /tmp/tebreak.ref.SVA:SVA_F.1d70cd96-ed12-40ed-ba2c-3495a4db7b20.fa ...
\end{verbatim}

\subsection{Filter the output table}

Please see the section on filtering for details.

First you'll need to build the hg19 mappability index:

\begin{verbatim}
cd lib
./human_mappability.sh
cd ..
\end{verbatim}

Once that is completed, filter the results from resolve.py:

\begin{verbatim}
scripts/filter_hg19.py --tabfile test/example.tab.txt > test/example.filtered.tab.txt
\end{verbatim}

If all went well, test/example.filtered.tab.txt should contain evidence for 5 transposable element insertions (2 L1s and 3 Alus). If it does not, please double check that all prerequisites are installed, read the rest of this document, try again, and e-mail me at adam.ewing@mater.uq.edu.au with error messages if you are still not having any luck.

\section{Insertion site discovery (tebreak.py)}
\subsection{Usage}
\begin{verbatim}
usage: tebreak.py [-h] -b BAM -r BWAREF [-p PROCESSES] [-c CHUNKS]
                  [-i INTERVAL_BED] [--minMWP MINMWP]
                  [--min_minclip MIN_MINCLIP] [--min_maxclip MIN_MAXCLIP]
                  [--min_sr_per_break MIN_SR_PER_BREAK]
                  [--min_consensus_score MIN_CONSENSUS_SCORE] [-m MASK]
                  [--rpkm_bam RPKM_BAM] [--max_fold_rpkm MAX_FOLD_RPKM]
                  [--max_ins_reads MAX_INS_READS]
                  [--min_split_reads MIN_SPLIT_READS]
                  [--min_prox_mapq MIN_PROX_MAPQ]
                  [--max_N_consensus MAX_N_CONSENSUS]
                  [--exclude_bam EXCLUDE_BAM]
                  [--exclude_readgroup EXCLUDE_READGROUP]
                  [--max_bam_count MAX_BAM_COUNT] [--map_tabix MAP_TABIX]
                  [--min_mappability MIN_MAPPABILITY]
                  [--max_disc_fetch MAX_DISC_FETCH] [--tmpdir TMPDIR]
                  [--pickle PICKLE] [--detail_out DETAIL_OUT] [--wg_rpkm]
                  [--no_rpkm] [--no_shared_mem]

Find inserted sequences vs. reference

optional arguments:
  -h, --help            show this help message and exit
  -b BAM, --bam BAM     target BAM(s): can be comma-delimited list
  -r BWAREF, --bwaref BWAREF
                        bwa/samtools indexed reference genome
  -p PROCESSES, --processes PROCESSES
                        split work across multiple processes
  -c CHUNKS, --chunks CHUNKS
                        split genome into chunks (default = # processes),
                        helps control memory usage
  -i INTERVAL_BED, --interval_bed INTERVAL_BED
                        BED file with intervals to scan
  --minMWP MINMWP       minimum Mann-Whitney P-value for split qualities
                        (default = 0.01)
  --min_minclip MIN_MINCLIP
                        min. shortest clipped bases per cluster (default = 3)
  --min_maxclip MIN_MAXCLIP
                        min. longest clipped bases per cluster (default = 10)
  --min_sr_per_break MIN_SR_PER_BREAK
                        minimum split reads per breakend (default = 1)
  --min_consensus_score MIN_CONSENSUS_SCORE
                        quality of consensus alignment (default = 0.9)
  -m MASK, --mask MASK  BED file of masked regions
  --rpkm_bam RPKM_BAM   use alternate BAM(s) for RPKM calculation: use
                        original BAMs if using reduced BAM(s) for -b/--bam
  --max_fold_rpkm MAX_FOLD_RPKM
                        ignore insertions supported by rpkm*max_fold_rpkm
                        reads (default = 10)
  --max_ins_reads MAX_INS_READS
                        maximum number of reads to use per insertion call
                        (default = 100000)
  --min_split_reads MIN_SPLIT_READS
                        minimum total split reads per insertion call (default
                        = 4)
  --min_prox_mapq MIN_PROX_MAPQ
                        minimum map quality for proximal subread (default =
                        10)
  --max_N_consensus MAX_N_CONSENSUS
                        exclude breakend seqs with > this number of N bases
                        (default = 4)
  --exclude_bam EXCLUDE_BAM
                        may be comma delimited
  --exclude_readgroup EXCLUDE_READGROUP
                        may be comma delimited
  --max_bam_count MAX_BAM_COUNT
                        maximum number of bams supporting per insertion
  --map_tabix MAP_TABIX
                        tabix-indexed BED of mappability scores
  --min_mappability MIN_MAPPABILITY
                        minimum mappability (default = 0.1; only matters with
                        --map_tabix)
  --max_disc_fetch MAX_DISC_FETCH
                        maximum number of discordant reads to fetch per
                        insertion site per BAM (default = 50)
  --tmpdir TMPDIR       temporary directory (default = /tmp)
  --pickle PICKLE       pickle output name
  --detail_out DETAIL_OUT
                        file to write detailed output
  --wg_rpkm             force calculate rpkm over whole genome
  --no_rpkm             do not filter sites by rpkm
  --no_shared_mem

\end{verbatim}

\subsection{Description}
Insertion sites are discovered through clustering and scaffolding of clipped reads. Additional support is obtained through local assembly of discordant read pairs, if applicable. Input requirements are minimal, consisting of one of more indexed BAM files and the reference genome corresponding to the alignments in the BAM files(s). Many additional options are available and recommended to improve performance and/or sensitivity.

\subsection{Input}
\paragraph{BAM Alignment input (-b/--bam)}
	BAMs ideally should adhere to SAM specification i.e. they should validate via picard\'s ValidateSamFile. BAMs should be sorted in coordinate order and indexed. BAMs may consist of either paired-end reads, fragment (single end) reads, or both. Multiple BAM files can be input in a comma-delimited list.
	
\paragraph{Reference genome (-r/--bwaref)}
	The reference genome should be the \textbf{same as that used to create the target BAM file}, specifically the chromosome names and lengths in the reference FASTA must be the same as in the BAM header. The reference must be indexed for bwa (\texttt{bwa index}) and indexed with samtools (\texttt{samtools faidx}).

\paragraph{Pickled output (--pickle)}
Output data in python's pickle format, meant for input to other scripts including resolve.py and picklescreen.py (in /scripts). Default is the basename of the input BAM with a .pickle extension.

\paragraph{Detailed human-readable output (--detail\_out)}
This is a file containing detailed information about consensus reads, aligned segments, and statistics for each putative insertion site detected. Note that this is done with minimal filtering, so these should not be used blindly. Default filename is tebreak.out

\paragraph{Additional options}
\begin{itemize}
\item -p/--processes :  Split work across multiple processes. Parallelism is accomplished through python's multiprocessing module. If specific regions are input via -i/--interval\_bed, these intervals will be distributed one per process. If a whole genome is to be analysed (no -i/--interval\_bed), the genome is split into chunks, one per process, unless a specific number of chunks is specified via -c/--chunks.
\item -i/--interval\_bed : BED file specifying intervals to be scanned for insertion evidence, the first three columns must be chromosome, start, end. A number of intervals equal to the value specified by -p/--processes will be searched in parallel. Overrides -c/--chunks.
\item --minMWP: Minimum value of Mann-Whitney P-value used to check similarity between the distribution of mapped base qualities versus clipped base qualities for a soft-clipped read (default = 0.01).
\item --min\_minclip : the shortest amount of soft clipping that will be considered (default = 3, minimum = 2).
\item --max\_minclip : For a given cluster of clipped reads, the greatest number of bases clipped form any read in the cluster must be at least this amount (default = 10).
\item --min\_sr\_per\_break : minimum number of split (clipped) reads required to form a cluster (default = 1)
\item --min\_consensus\_score : minimum quality score for the scaffold created from clipped reads (default = 0.95)
\item -m/--mask : BED file of regions to mask. Reads will not be considered if they fall into regions in this file.
\item --rpkm\_bam : use alternate BAM file(s) for RPKM calculation for avoiding over-aligned regions (useful for subsetted BAMs).
\item --max\_fold\_rpkm : reject cluster if RPKM for clustered region is greater than the mean RPKM by this factor (default = 10)
\item --max\_ins\_reads : maximum number of reads per insertion call (default = 1000)
\item --min\_split\_reads : minimum total split (clipped) read count per insertion (default = 4)
\item --min\_prox\_mapq : minimum mapping quality for proximal (within-cluster) alignments (default = 10)
\item --max\_N\_consensus : exclude reads and consensus breakends with greater than this number of N (undefined) bases (default = 4)
\item --exclude\_bam : only consider clusters that do not include reads from these BAM(s) (may be comma-delimited list)
\item --exclude\_readgroup : only consider clusters that to not include reads from these readgroup(s) (may be comma-delimited list)
\item --max\_bam\_count : set maximum number of BAMs involved per insertion
\item --insertion\_library : pre-select insertions containing sequence from specified FASTA file (not generally recommended but may improve running time in some instances)
\item --map\_tabix : tabix-indexed BED of mappability scores. Generate for human with script in lib/human\_mappability.sh.
\item --min\_mappability : minimum mappability for cluster (default = 0.5; only effective if --map\_tabix is also specified)
\item --max\_disc\_fetch : maximum number of discordant mates to fetch per insertion site per BAM. Sites with more than this number of discordant reads associated will be downsampled. This helps with runtime as fetching discordant rates is time-consuming (default = 50).
\item --tmpdir : directory for temporary files (default = /tmp)
\item --wg\_rpkm : calculate average RPKM using entire genome instead of regions in -i/--interval\_bed
\item --no\_rpkm : disable filtering pileup depth by RPKM.
\item --no\_shared\_mem : By default, tebreak.py will try to use \texttt{bwa shm} to load the reference genome into shared memory as this is much more efficient for multiprocessing. This option disables shared memory.

\end{itemize}


\section{Resolution of specific insertion types (resolve.py)}
\subsection{Usage}
\begin{verbatim}
usage: resolve.py [-h] -p PICKLE [-t PROCESSES] -i INSLIB_FASTA
                  [-m FILTER_BED] [-v] [-o OUT]
                  [--max_bam_count MAX_BAM_COUNT]
                  [--min_ins_match MIN_INS_MATCH] [--minmatch MINMATCH]
                  [--mindiscord MINDISCORD] [-a ANNOTATION_TABIX]
                  [--refoutdir REFOUTDIR] [--skip_align] [--use_rg]
                  [--keep_all_tmp_bams] [--detail_out DETAIL_OUT] [--unmapped]
                  [--te] [--usecachedLAST] [--uuid_list UUID_LIST]
                  [--callmuts] [--tmpdir TMPDIR]

Resolve insertions from TEbreak data

optional arguments:
  -h, --help            show this help message and exit
  -p PICKLE, --pickle PICKLE
                        pickle file output from tebreak.py
  -t PROCESSES, --processes PROCESSES
                        split work across multiple processes
  -i INSLIB_FASTA, --inslib_fasta INSLIB_FASTA
                        reference for insertions (not genome)
  -m FILTER_BED, --filter_bed FILTER_BED
                        BED file of regions to mask
  -v, --verbose         output status information
  -o OUT, --out OUT     output table
  --max_bam_count MAX_BAM_COUNT
                        skip sites with more than this number of BAMs (default
                        = no limit)
  --min_ins_match MIN_INS_MATCH
                        minumum match to insertion library
  --minmatch MINMATCH   minimum match to reference genome
  --mindiscord MINDISCORD
                        minimum mapped discordant read count
  -a ANNOTATION_TABIX, --annotation_tabix ANNOTATION_TABIX
                        can be comma-delimited list
  --refoutdir REFOUTDIR
                        output directory for generating tebreak references
                        (default=tebreak_refs)
  --skip_align          skip re-alignment of discordant ends to ref insertion
  --use_rg              use RG instead of BAM filename for samples
  --keep_all_tmp_bams   leave ALL temporary BAMs (warning: lots of files!)
  --detail_out DETAIL_OUT
                        file to write detailed output
  --unmapped            report insertions that do not match insertion library
  --te                  set if insertion library is transposons
  --usecachedLAST       try to used cached LAST db, if found
  --uuid_list UUID_LIST
                        limit resolution to UUIDs in first column of input
                        list (can be tabular output from previous resolve.py
                        run)
  --callmuts            detect changes in inserted seq. vs ref. (requires
                        bcftools)
  --tmpdir TMPDIR       directory for temporary files

\end{verbatim}

\subsection{Description}
This script is the second step in insertion analysis via TEBreak, it is separated from the initial insertion discovery script (tebreak.py) to facilitate running multiple different analyses on the same set of putative insertion sites (e.g. detecting transposable elements, viral insertions, processed transcript insertions, and novel sequence insertions from the same WGS data).

\subsection{Input}
\paragraph{Insertion call input (-p/--pickle)}
	This is the 'pickle' containing information about putative insertion sites derived from tebreak.py (filename specified by --pickle).
	
\paragraph{Reference genome (-i/--inslib}
A FASTA file containing template insertion sequences (e.g. reference transposable elements, viral sequences, mRNAs, etc.). For transposable elements, sequence superfamilies and subfamilies can be specified by separating with a colon (:) as follows:

\begin{verbatim}
>ALU:AluYa5
GGCCGGGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGGCGGGCGGATCACGAGGTCAGGAGATCG
AGACCATCCCGGCTAAAACGGTGAAACCCCGTCTCTACTAAAAATACAAAAAATTAGCCGGGCGTAGTGGCGGGCGCCT
GTAGTCCCAGCTACTTGGGAGGCTGAGGCAGGAGAATGGCGTGAACCCGGGAGGCGGAGCTTGCAGTGAGCCGAGATCC
CGCCACTGCACTCCAGCCTGGGCGACAGAGCGAGACTCCGTCTCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
\end{verbatim}

\paragraph{Detailed human-readable output (--detail\_out)}
This is a file containing detailed information about consensus reads, aligned segments, and statistics for each putative insertion site detected. Note that this is done with minimal filtering, so these should not be used blindly. Default filename is the input BAM filename minus the .bam extension plus .resolve.out

\paragraph{Tabular output (-o/--out)}
Filename for the output table which is usually the primary means to assess insertion detection. This format is described in detail later in this document. Default filename is the input BAM filename minus the .bam extension plus .table.txt

\paragraph{Additional options}
\begin{itemize}
\item -t/--threads : Split work across multiple processes.
\item -m/--filter\_bed : BED file of regions to mask (will not be output)
\item -v/--verbose : Output status information.
\item --max\_bam\_count : do not analyse insertions represented by more than this number of BAMs (default = no filter)
\item --min\_ins\_match : minimum percent match to insertion library
\item --minmatch : minimum percent match to reference genome
\item --mindiscord : minimum number of discordant reads associated with insertion sites
\item --annotation\_tabix : tabix-indexed file, entries overlapping insertions will be annotated in output
\item --refoutdir : non-temporary output directory for various references generated by resolve.py. This includes LAST references for the insertion library and insertion-specific BAMs if --keep\_ins\_bams is enabled.
\item --skip\_align : skip insertion-specific realignment of split/discordant reads (not recommended on first pass)
\item --use\_rg : use the readgroup name instead of the BAM name to count and annotate samples
\item --keep\_all\_tmp\_bams : retain all temporary BAMs in temporary directory (warning: this can easily be in excess of 100000 files for WGS data and may lead to unhappy filesystems).
\item --unmapped : also report insertions that do not match the insertion library
\item --te : enable additional filtering specific to transposable element insertions
\item --usecachedLAST : useful if -i/--inslib FASTA is large, you can use a pre-built LAST reference (in --refoutdir) e.g. if it was generated on a previous run.
\item --uuid\_list : limit analysis to set of UUIDs in the first column of specified file (generally, this is the table output by a previous run of resolve.py) - this is useful for changing annotations, altering parameters, debugging, etc.
\item --callmuts : reports changes in inserted sequence vs insertion reference in the 'Variants' column of the tabular output
\item --tmpdir : directory for temporary files (default is /tmp)
\end{itemize}

\subsection{Output}
A table (tab-delimited) is output (with a header) is written to STDOUT, so I would recommend redirecting stdout of resolve.py to a file. The output contains the following columns:

\begin{itemize}
\item UUID : Unique identifier
\item Chromosome : Chromosome
\item Left\_Extreme : Coordinate of the left-most reference base mapped to a read supporting the insertion
\item Right\_Extreme : Coordinate of the right-most reference base mapped to a read supporting the insertion
\item 5\_Prime\_End : Breakend corresponding to the 5' end of the inserted sequence (where 5' is can be defined e.g. for transposable elements)
\item 3\_Prime\_End : Breakend corresponding to the 3' end of the inserted sequence (where 3' is can be defined e.g. for transposable elements)
\item Superfamily : Superfamily of insertions of superfamily is defined (see option -i/--inslib in resolve.py)
\item Subfamily : Subfamily of insertions of subfamily is defined (see option -i/--inslib in resolve.py)
\item TE\_Align\_Start : alignment start position within inserted sequence relative to reference
\item TE\_Align\_End : alignment end position within inserted sequence relative to reference
\item Orient\_5p : Orientation derived from the 5' end of the insertion (if 5' is defined), assuming insertion reference is read 5' to 3'
\item Orient\_3p : Orientation derived from the 3' end of the insertion (if 3' is defined), assuming insertion reference is read 5' to 3'
\item Inversion : If Orient\_5p and Orient\_3p disagree, there may be an inversion in the inserted sequence relative to the reference sequence for the insertion
\item 5p\_Elt\_Match : Fraction of bases matched to reference for inserted sequence on insertion segment of 5' supporting contig
\item 3p\_Elt\_Match : Fraction of bases matched to reference for inserted sequence on insertion segment of 3' supporting contig
\item 5p\_Genome\_Match : Fraction of bases matched to reference genome on genomic segment of 5' supporting contig
\item 3p\_Genome\_Match : Fraction of bases matched to reference genome on genomic segment of 3' supporting contig
\item Split\_reads\_5prime : Number of split (clipped) reads supporting 5' end of the insertion
\item Split\_reads\_3prime : Number of split (clipped) reads supporting 5' end of the insertion
\item Remapped\_Discordant : Number of discordant read ends re-mappable to insertion reference sequence
\item Remapped\_Splitreads : Number of split reads re-mappable to insertion reference sequence
\item 5p\_Cons\_Len : Length of 5' consensus sequence (Column Consensus\_5p)
\item 3p\_Cons\_Len : Length of 3' consensus sequence (Column Consensus\_3p)
\item 5p\_Improved : Whether the 5' consensus sequence was able to be improved through local assembly in tebreak.py
\item 3p\_Improved : Whether the 3' consensus sequence was able to be improved through local assembly in tebreak.py
\item TSD\_3prime : Target site duplication (if present) based on 5' overlap on consensus sequence
\item TSD\_5prime : Target site duplication (if present) based on 3' overlap on consensus sequence (can be different from 5' end, but in many cases it is advisable to filter out putative insertions that disagree on TSDs)
\item Sample\_count : Number of samples (based on BAM files or readgroups, depending on --use\_rg option in resolve.py)
\item Sample\_support : Per-sample split read count supporting insertion presence (Sample$\vert$Count)
\item Genomic\_Consensus\_5p : Consensus sequence for 5' supporting contig assembled from genome side of breakpoint
\item Genomic\_Consensus\_3p : Consensus sequence for 3' supporting contig assembled from genome side of breakpoint
\item Insert\_Consensus\_5p : Consensus sequence for 5' supporting contig assembled from insertion side of breakpoint
\item Insert\_Consensus\_3p : Consensus sequence for 3' supporting contig assembled from insertion side of breakpoint
\item Variants : if --callmuts option given to resolve.py, this is a list of changes detected between inserted sequence and insertion reference sequence
\end{itemize}

Additional columns may be present depending on annotation options:

\begin{itemize}
\item NonRef : non-reference annotation, made with scripts/annotate.py --nonref (column name could vary)
\item Mappability : added by filter\_hg19.py, measure of mappability/alignability over the interval defined by left and right extrema
\item ExonerateRealign : added by filter\_hg19.py if run with --insref, reflects results of realigning consensus contigs to element consensus ith Exonerate. Will probably remove in the future.
\item ChimeraBaseCount : Number of bases overlapping between insertion prediction and target site. Short overlaps may reflect microhomology at the insertion site, longer overlaps may indicate chimeric sequences which are more likely to be false positive (requires filter\_hg19.py run with --chimera)
\item InsSiteHomology : sequence of overlapped bases (length = ChimeraBaseCount) from consensus sequence (requires filter\_hg19.py run with --chimera)
\end{itemize}

\section{Filtering}

\subsection{Pre-filtering}
In some cases it is not necessary to analyse the entire genome. Regions of interest in BED format may be input to tebreak.py via the -i/--inverval\_bed option.

\begin{itemize}
\item If paired-end reads are present, it is possible to pre-select regions where insertions may be indicated by discordant paired-end mappings. This can be accomplished using the script 'discoreads.py' which is in the scripts directory of the TEBreak distribution. 
\item For whole genome sequencing (WGS) data, it is only the soft-clipped reads and reads in discordant pairs that are informative; the rest of the mapped reads can be discarded. This can be accomplished using the script 'reduce\_bam.py', located in the scripts directory. Pre-processing with this script may yield lower runtime due to less disk access.
\item For sequence derived from targeted sequencing methods (e.g. whole exome sequencing), it may be useful to only analyse regions covered to at least a certain read depth. This can be accomplished using the script 'covered\_segments.py' in the scripts directory.
\item To improve the runtime of resolve.py over large datasets (e.g. WGS) the 'pickle' generated by tebreak.py can be reduced using picklescreen.py (in the scripts directory). This will pre-align all junction reads to an insertion reference library, reducing the number of candidates for further analysis by resolve.py.
\item For larger cohorts, splitting the 'pickle' file up into per-chromosome files may be required to reduce memory usage. This can be accomplished with the 'picklesplit.py' script in the scripts directory.
\end{itemize}

\subsection{Post-filtering}
Generally additional filtering is required on the tabular output to achieve the desired level of accuracy. For example, the positions of transposable element insertions should be filtered against the locations of transposable element insertions in the reference genome used for input to tebreak.py. For humans aligned to hg19, a suggested set of filters is implemented in filter\_hg19.py in the scripts folder.

\end{document}


